{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.models import Model\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense,Flatten,Conv2D,Activation,Dropout\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.layers import MaxPool2D\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWF9-wuiFkee",
    "outputId": "e16e1fa7-e6d5-44c9-e671-f34242951de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dew', 'fogsmog', 'frost', 'glaze', 'hail', 'lightning', 'rain', 'rainbow', 'rime', 'sandstorm', 'snow']\n"
     ]
    }
   ],
   "source": [
    "# VGG16\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "data_dir_list = os.listdir(\"Dataset/Train\")\n",
    "print(data_dir_list)\n",
    "path, dirs, files = next(os.walk(\"Dataset/Train\"))\n",
    "file_count = len(files)\n",
    "original_dataset_dir = \"/Dataset\"\n",
    "base_dir = 'weather-data/'\n",
    "os.mkdir(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "smSEhUsY8VIH"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "os.mkdir(validation_dir)\n",
    "\n",
    "#I am creating folders myself\n",
    "\n",
    "train_dew_dir = os.path.join(train_dir, 'dew')\n",
    "os.mkdir(train_dew_dir)\n",
    "\n",
    "train_fogsmog_dir = os.path.join(train_dir, 'fogsmog')\n",
    "os.mkdir(train_fogsmog_dir)\n",
    "\n",
    "train_frost_dir = os.path.join(train_dir, 'frost')\n",
    "os.mkdir(train_frost_dir)\n",
    "\n",
    "train_glaze_dir = os.path.join(train_dir, 'glaze')\n",
    "os.mkdir(train_glaze_dir)\n",
    "\n",
    "\n",
    "train_hail_dir = os.path.join(train_dir, 'hail')\n",
    "os.mkdir(train_hail_dir)\n",
    "\n",
    "train_lightning_dir = os.path.join(train_dir, 'lightning')\n",
    "os.mkdir(train_lightning_dir)\n",
    "\n",
    "train_rain_dir = os.path.join(train_dir, 'rain')\n",
    "os.mkdir(train_rain_dir)\n",
    "\n",
    "train_rainbow_dir = os.path.join(train_dir, 'rainbow')\n",
    "os.mkdir(train_rainbow_dir)\n",
    "\n",
    "train_rime_dir = os.path.join(train_dir, 'rime')\n",
    "os.mkdir(train_rime_dir)\n",
    "\n",
    "train_sandstorm_dir = os.path.join(train_dir, 'sandstorm')\n",
    "os.mkdir(train_sandstorm_dir)\n",
    "\n",
    "train_snow_dir = os.path.join(train_dir, 'snow')\n",
    "os.mkdir(train_snow_dir)\n",
    "\n",
    "\n",
    "\n",
    "#validation new folders\n",
    "\n",
    "val_dew_dir = os.path.join(validation_dir, 'dew')\n",
    "os.mkdir(val_dew_dir)\n",
    "\n",
    "val_fogsmog_dir = os.path.join(validation_dir, 'fogsmog')\n",
    "os.mkdir(val_fogsmog_dir)\n",
    "\n",
    "val_frost_dir = os.path.join(validation_dir, 'frost')\n",
    "os.mkdir(val_frost_dir)\n",
    "\n",
    "val_glaze_dir = os.path.join(validation_dir, 'glaze')\n",
    "os.mkdir(val_glaze_dir)\n",
    "\n",
    "val_hail_dir = os.path.join(validation_dir, 'hail')\n",
    "os.mkdir(val_hail_dir)\n",
    "\n",
    "val_lightning_dir = os.path.join(validation_dir, 'lightning')\n",
    "os.mkdir(val_lightning_dir)\n",
    "\n",
    "val_rain_dir = os.path.join(validation_dir, 'rain')\n",
    "os.mkdir(val_rain_dir)\n",
    "\n",
    "val_rainbow_dir = os.path.join(validation_dir, 'rainbow')\n",
    "os.mkdir(val_rainbow_dir)\n",
    "\n",
    "val_rime_dir = os.path.join(validation_dir, 'rime')\n",
    "os.mkdir(val_rime_dir)\n",
    "\n",
    "val_sandstorm_dir = os.path.join(validation_dir, 'sandstorm')\n",
    "os.mkdir(val_sandstorm_dir)\n",
    "\n",
    "val_snow_dir = os.path.join(validation_dir, 'snow')\n",
    "os.mkdir(val_snow_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tSvYTsmOauIm"
   },
   "outputs": [],
   "source": [
    "# %rm -rf /content/weather-data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kwVhFv_SGQY_"
   },
   "outputs": [],
   "source": [
    "dew_SOURCE_DIR = \"Dataset/Train/dew/\"\n",
    "TRAINING_dew_DIR = 'weather-data/train/dew/'\n",
    "VALID_dew_DIR = 'weather-data/validation/dew/'\n",
    "\n",
    "fogsmog_SOURCE_DIR = \"Dataset/Train/fogsmog/\"\n",
    "TRAINING_fogsmog_DIR = 'weather-data/train/fogsmog/'\n",
    "VALID_fogsmog_DIR = 'weather-data/validation/fogsmog/'\n",
    "\n",
    "frost_SOURCE_DIR = \"Dataset/Train/frost/\"\n",
    "TRAINING_frost_DIR = 'weather-data/train/frost/'\n",
    "VALID_frost_DIR = 'weather-data/validation/frost/'\n",
    "\n",
    "glaze_SOURCE_DIR = \"Dataset/Train/glaze/\"\n",
    "TRAINING_glaze_DIR = 'weather-data/train/glaze/'\n",
    "VALID_glaze_DIR = 'weather-data/validation/glaze/'\n",
    "\n",
    "hail_SOURCE_DIR = \"Dataset/Train/hail/\"\n",
    "TRAINING_hail_DIR = 'weather-data/train/hail/'\n",
    "VALID_hail_DIR = 'weather-data/validation/hail/'\n",
    "\n",
    "\n",
    "lightning_SOURCE_DIR = \"Dataset/Train/lightning/\"\n",
    "TRAINING_lightning_DIR = 'weather-data/train/lightning/'\n",
    "VALID_lightning_DIR = 'weather-data/validation/lightning/'\n",
    "\n",
    "\n",
    "rain_SOURCE_DIR = \"Dataset/Train/rain/\"\n",
    "TRAINING_rain_DIR = 'weather-data/train/rain/'\n",
    "VALID_rain_DIR = 'weather-data/validation/rain/'\n",
    "\n",
    "\n",
    "rainbow_SOURCE_DIR = \"Dataset/Train/rainbow/\"\n",
    "TRAINING_rainbow_DIR = 'weather-data/train/rainbow/'\n",
    "VALID_rainbow_DIR = 'weather-data/validation/rainbow/'\n",
    "\n",
    "\n",
    "rime_SOURCE_DIR =\"Dataset/Train/rime/\"\n",
    "TRAINING_rime_DIR = 'weather-data/train/rime/'\n",
    "VALID_rime_DIR = 'weather-data/validation/rime/'\n",
    "\n",
    "\n",
    "sandstorm_SOURCE_DIR = \"Dataset/Train/sandstorm/\"\n",
    "TRAINING_sandstorm_DIR = 'weather-data/train/sandstorm/'\n",
    "VALID_sandstorm_DIR = 'weather-data/validation/sandstorm/'\n",
    "\n",
    "snow_SOURCE_DIR =\"Dataset/Train/snow/\"\n",
    "TRAINING_snow_DIR = 'weather-data/train/snow/'\n",
    "VALID_snow_DIR = 'weather-data/validation/snow/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "A2ldTLShGbtj"
   },
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAINING, VALIDATION, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    valid_length = int(len(files) - training_length)\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    valid_set = shuffled_set[training_length:]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in valid_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = VALIDATION + filename\n",
    "        copyfile(this_file, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6rDzzaxS87zW"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from shutil import copyfile\n",
    "\n",
    "split_size = 0.80\n",
    "\n",
    "split_data(dew_SOURCE_DIR, TRAINING_dew_DIR, VALID_dew_DIR, split_size)\n",
    "split_data(fogsmog_SOURCE_DIR, TRAINING_fogsmog_DIR, VALID_fogsmog_DIR, split_size)\n",
    "split_data(frost_SOURCE_DIR, TRAINING_frost_DIR, VALID_frost_DIR, split_size)\n",
    "split_data(glaze_SOURCE_DIR, TRAINING_glaze_DIR, VALID_glaze_DIR , split_size)\n",
    "split_data(hail_SOURCE_DIR , TRAINING_hail_DIR, VALID_hail_DIR, split_size)\n",
    "split_data(lightning_SOURCE_DIR , TRAINING_lightning_DIR, VALID_lightning_DIR, split_size)\n",
    "split_data(rain_SOURCE_DIR ,TRAINING_rain_DIR, VALID_rain_DIR, split_size)\n",
    "split_data(rainbow_SOURCE_DIR ,TRAINING_rainbow_DIR, VALID_rainbow_DIR, split_size)\n",
    "split_data(rime_SOURCE_DIR  ,TRAINING_rime_DIR, VALID_rime_DIR, split_size)\n",
    "split_data(sandstorm_SOURCE_DIR,TRAINING_sandstorm_DIR, VALID_sandstorm_DIR, split_size)\n",
    "split_data(snow_SOURCE_DIR ,TRAINING_snow_DIR, VALID_snow_DIR, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KhZJ_xdd_VhG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "w9fhSZNu_all"
   },
   "outputs": [],
   "source": [
    "img_width=350; img_height=350\n",
    "batch_size=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMspbg4L_dTG",
    "outputId": "96a4ec80-b859-4531-81a3-b9d7a3b60ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4437 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = 'weather-data/train/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255.0,\n",
    "                                   rotation_range=30,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(350, 350))\n",
    "#train_generator = cv2.cvtColor(train_generator, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hW3KjQz_rXi",
    "outputId": "4254d243-6a0e-4127-e4a3-feca77a569c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1114 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_DIR = 'weather-data/validation/'\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1/255.0)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode='categorical',\n",
    "                                                              target_size=(350, 350)\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "STMUpcmZ__no"
   },
   "outputs": [],
   "source": [
    "callbacks = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "# autosave best Model\n",
    "#best_model_file = 'CNN_aug_best_weights.h5'\n",
    "#best_model = ModelCheckpoint(best_model_file, monitor='val_acc', verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "LRtQ7UBBoIM5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 348, 348, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 174, 174, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 172, 172, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 86, 86, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 84, 84, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 42, 42, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 40, 40, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 20, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 51200)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 500)               25600500  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 500)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 400)               200400    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 400)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 350)               140350    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 350)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 200)               70200     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 11)                2211      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,143,837\n",
      "Trainable params: 26,143,837\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.Sequential([\n",
    "                            tf.keras.layers.Conv2D(32, (3,3), activation=\"relu\", input_shape = (350,350,3)),\n",
    "                            tf.keras.layers.MaxPooling2D(2,2),\n",
    "                            tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "                            tf.keras.layers.MaxPooling2D(2,2),\n",
    "                            tf.keras.layers.Conv2D(64, (3,3), activation=\"relu\"),\n",
    "                            tf.keras.layers.MaxPooling2D(2,2),\n",
    "                            tf.keras.layers.Conv2D(128, (3,3), activation=\"relu\"),\n",
    "                            tf.keras.layers.MaxPooling2D(2,2),\n",
    "                            tf.keras.layers.Flatten(),\n",
    "                            #adding the hidden layer\n",
    "                            tf.keras.layers.Dense(500,activation=\"relu\"),\n",
    "                            tf.keras.layers.Dropout(0.1),\n",
    "                            tf.keras.layers.Dense(400,activation=\"relu\"),\n",
    "                            tf.keras.layers.Dropout(0.2),\n",
    "                            tf.keras.layers.Dense(350,activation=\"relu\"),\n",
    "                            tf.keras.layers.Dropout(0.3),\n",
    "                            tf.keras.layers.Dense(200,activation=\"relu\"),\n",
    "                            tf.keras.layers.Dropout(0.4),\n",
    "                            #then adding the output layer\n",
    "                            tf.keras.layers.Dense(11,activation=\"softmax\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PG6Sj799oNqD",
    "outputId": "85531ae9-a61d-4b1b-d907-97c5e158c7cb"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics =['accuracy'])\n",
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=75,\n",
    "                              verbose=1,\n",
    "                              validation_data=validation_generator,\n",
    "                              callbacks = [callbacks]\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AU0PFD0n_1Qj"
   },
   "outputs": [],
   "source": [
    "model.save(\"cnn_75.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QhMosXvgFg0v",
    "outputId": "aaebec0f-e373-4991-fcce-a939d1bfe399"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"cnn_75.h5\")\n",
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "oGv2nuKlPbd6"
   },
   "outputs": [],
   "source": [
    "callbacks = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "# autosave best Model\n",
    "best_model_file = 'CNN_aug_best_weights.h5'\n",
    "best_model = ModelCheckpoint(best_model_file, monitor='val_acc', verbose = 1, save_best_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AlexNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 55, 55, 96)        34944     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 55, 55, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 27, 27, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 27, 27, 96)       384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 27, 27, 256)       614656    \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 27, 27, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 13, 13, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 13, 13, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 13, 13, 384)       0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 13, 13, 384)       0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 13, 13, 384)      1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 13, 13, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 6, 6, 256)        1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 9216)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4096)              37752832  \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 4096)             16384     \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 11)                45067     \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 11)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 58,364,683\n",
      "Trainable params: 58,345,547\n",
      "Non-trainable params: 19,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D,BatchNormalization,LayerNormalization\n",
    "\n",
    "# here we are using 'BatchNormalization' instead of 'LayerNormalization'\n",
    "\n",
    "\n",
    "\n",
    "# (3) Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(227,227,3), kernel_size=(11,11),\\\n",
    " strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling \n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# Passing it to a dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "#  output Layer \n",
    "model.add(Dense(11))\n",
    "\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(lr=0.0001)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "#hist = model.fit_generator(steps_per_epoch=100,generator=train_generator, validation_data= validation_generator, validation_steps=10,epochs=100,callbacks=[early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZvJg0efHWbSy"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "IMAGE_SIZE=224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iZPPzRQceQBl"
   },
   "source": [
    "### VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4437 images belonging to 11 classes.\n",
      "Found 1114 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAINING_DIR = 'weather-data/train/'\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1/255.0,\n",
    "                                   rotation_range=30,\n",
    "                                   zoom_range=0.4,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(224, 224))\n",
    "VALIDATION_DIR = 'weather-data/validation/'\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale = 1/255.0)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
    "                                                              batch_size=batch_size,\n",
    "                                                              class_mode='categorical',\n",
    "                                                              target_size=(224, 224)\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "j32jY5D1eOoL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "IMAGE_SIZE=224\n",
    "def VGG16():\n",
    "  #224\n",
    "  with tf.device('/device:GPU:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(input_shape=(IMAGE_SIZE,IMAGE_SIZE,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(4096, activation='relu', name='fc1'))#256\n",
    "    model.add(Dense(4096, activation='relu', name='fc2'))#128\n",
    "    model.add(Dense(11, activation='softmax', name='output'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "VX_0iUX7n5H8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 112, 112, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 14, 14, 512)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " vgg16 (MaxPooling2D)        (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " output (Dense)              (None, 11)                45067     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,305,611\n",
      "Trainable params: 134,305,611\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002961B95B070> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002961B948190> True\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000002961B902A00> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002961B860BE0> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002960F2D0370> True\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000002961A6A7A00> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002961A7E7190> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002960F2D0EB0> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002961B9410D0> True\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000002961B948F10> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002961B90EC10> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002961B93A100> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029619FBBA90> True\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000002961B941D00> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002961B9192E0> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x0000029619FADF10> True\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002961A6A1D30> True\n",
      "<keras.layers.pooling.max_pooling2d.MaxPooling2D object at 0x000002961A7B5F40> True\n",
      "<keras.layers.reshaping.flatten.Flatten object at 0x000002961B8F5A00> True\n",
      "<keras.layers.core.dense.Dense object at 0x000002961B898130> True\n",
      "<keras.layers.core.dense.Dense object at 0x000002961B86CF10> True\n",
      "<keras.layers.core.dense.Dense object at 0x0000029619F9EEE0> True\n"
     ]
    }
   ],
   "source": [
    "model=VGG16()\n",
    "\n",
    "model.summary()\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "opt = Adam(lr=0.0001)#SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=10)\n",
    "#mc = ModelCheckpoint('/content/drive/MyDrive/best_model.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n",
    "H = model.fit_generator(train_generator,validation_data=validation_generator,epochs=30,verbose=1,callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"NNweights.h5\")\n",
    "model.evaluate(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "paExzsc1M0lD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_filenames = os.listdir(\"NNTests\")\n",
    "test_df = pd.DataFrame({\n",
    "    'filename': test_filenames\n",
    "})\n",
    "nb_samples = test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z3VoKjC1NBGp",
    "outputId": "9b377754-008e-43e3-86fb-9d8427a2e488"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "test_gen = ImageDataGenerator(rescale = 1/255.0,\n",
    "                                   rotation_range=30,\n",
    "                                   zoom_range=0.4,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "\n",
    "# train_generator = train_datagen.flow_from_directory(TRAIN_DIR_FILE,\n",
    "#                                                     batch_size=15,\n",
    "#                                                     class_mode='categorical',\n",
    "#                                                     target_size=(IMAGE_SIZE, IMAGE_SIZE))\n",
    "\n",
    "\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "   test_df, \n",
    "   \"NNTests\",\n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    target_size=(350, 350),\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ju7zxMdsNFis"
   },
   "outputs": [],
   "source": [
    "predict = model.predict(test_generator, steps=np.ceil(nb_samples/16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9CcQG_HNHeO"
   },
   "outputs": [],
   "source": [
    "test_df['category'] = np.argmax(predict, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8GSMqmS4NJXa"
   },
   "outputs": [],
   "source": [
    "submission_df = test_df.copy()\n",
    "submission_df['image_name'] = submission_df['filename']\n",
    "submission_df['label'] = submission_df['category']\n",
    "submission_df.drop(['filename', 'category'], axis=1, inplace=True)\n",
    "submission_df.to_csv('submission_cnn_final', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Oq8b8D0MivhP"
   ],
   "name": "Copy_of_Multiclass_Classification_CNN_DataAug.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
